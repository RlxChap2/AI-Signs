from flask import Flask, render_template, Response
import cv2
import mediapipe as mp
import numpy as np
from collections import deque

app = Flask(__name__)

# Ø¥Ø¹Ø¯Ø§Ø¯ Mediapipe
mpHands = mp.solutions.hands
hands = mpHands.Hands(static_image_mode=False,
                      max_num_hands=1,
                      min_detection_confidence=0.7,
                      min_tracking_confidence=0.7)
mpDraw = mp.solutions.drawing_utils

# Ù…ØªØºÙŠØ± Ù„Ø­ÙØ¸ Ø¢Ø®Ø± Ø¥Ø­Ø¯Ø§Ø«ÙŠØ§Øª Ø§Ù„Ù…Ø¹ØµÙ… Ù„Ù„ÙƒØ´Ù Ø¹Ù† Ø§Ù„ØªÙ„ÙˆÙŠØ­
hand_history = deque(maxlen=10)

# Ø¯Ø§Ù„Ø© ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ÙØ±ÙŠÙ…Ø§Øª Ù…Ù† Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§
def generate_frames():
    cap = cv2.VideoCapture(0)
    gesture = "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¥Ø´Ø§Ø±Ø©"

    while True:
        success, img = cap.read()
        if not success:
            break

        imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        results = hands.process(imgRGB)

        h, w, c = img.shape

        if results.multi_hand_landmarks:
            for handLms in results.multi_hand_landmarks:
                lmList = []
                for id, lm in enumerate(handLms.landmark):
                    cx, cy = int(lm.x * w), int(lm.y * h)
                    lmList.append((cx, cy))

                if lmList:
                    # ---------------------------
                    # ğŸ‘‡ Ù…Ù†Ø·Ù‚ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¥Ø´Ø§Ø±Ø©
                    # ---------------------------
                    fingers = []

                    # Ø§Ù„Ø¥Ø¨Ù‡Ø§Ù… (Ù…Ø­ÙˆØ± Ø£ÙÙ‚ÙŠ)
                    if lmList[4][0] > lmList[3][0]:
                        fingers.append(1)
                    else:
                        fingers.append(0)

                    # Ø¨Ø§Ù‚ÙŠ Ø§Ù„Ø£ØµØ§Ø¨Ø¹ (Ù…Ø­ÙˆØ± Ø¹Ù…ÙˆØ¯ÙŠ)
                    tips = [8, 12, 16, 20]
                    for tip in tips:
                        fingers.append(1 if lmList[tip][1] < lmList[tip - 2][1] else 0)

                    # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ù…Ù† Ø§Ù„Ù†Ù…Ø·
                    patterns = {
                        (0, 0, 0, 0, 0): "Ù‚Ø¨Ø¶Ø© âœŠ",
                        (1, 1, 1, 1, 1): "ÙŠØ¯ Ù…ÙØªÙˆØ­Ø© âœ‹",
                        (0, 1, 0, 0, 0): "Ø³Ø¨Ø§Ø¨Ø© â˜ï¸",
                        (1, 0, 0, 0, 0): "Ø¥Ø¹Ø¬Ø§Ø¨ ğŸ‘",
                        (0, 1, 1, 0, 0): "Ù†ØµØ± âœŒï¸",
                        (0, 1, 1, 1, 1): "Ø£Ø±Ø¨Ø¹ Ø£ØµØ§Ø¨Ø¹ ğŸ–ï¸",
                        (1, 0, 0, 0, 1): "Ø§ØªØµØ§Ù„ ğŸ¤™",
                    }

                    gesture = patterns.get(tuple(fingers), "ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ")

                    # Ø§Ù„ØªÙ„ÙˆÙŠØ­ (Wave Detection)
                    wrist_x = lmList[0][0]
                    hand_history.append(wrist_x)

                    if len(hand_history) == hand_history.maxlen:
                        diffs = [hand_history[i + 1] - hand_history[i] for i in range(len(hand_history) - 1)]
                        if max(diffs) - min(diffs) > 50:
                            gesture = "ğŸ‘‹ ØªÙ„ÙˆÙŠØ­"

                    # Ø±Ø³Ù… Ø§Ù„Ù†Ù‚Ø§Ø· ÙˆØ§Ù„Ø®Ø·ÙˆØ·
                    mpDraw.draw_landmarks(img, handLms, mpHands.HAND_CONNECTIONS)

        # Ø¹Ø±Ø¶ Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ© Ø¹Ù„Ù‰ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§
        cv2.putText(img, f"Ø§Ù„Ø¥Ø´Ø§Ø±Ø©: {gesture}", (10, 50),
                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 3)

        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ù„Ù„ÙÙŠØ¯ÙŠÙˆ Ø§Ù„Ø¨Ø«Ù‘ÙŠ
        ret, buffer = cv2.imencode('.jpg', img)
        frame = buffer.tobytes()
        yield (b'--frame\r\n'
               b'Content-Type: image/jpeg\r\n\r\n' + frame + b'\r\n')

    cap.release()


@app.route('/')
def index():
    return render_template('index.html')


@app.route('/video_feed')
def video_feed():
    return Response(generate_frames(), mimetype='multipart/x-mixed-replace; boundary=frame')


if __name__ == "__main__":
    app.run(debug=True)
